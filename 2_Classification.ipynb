{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGvumfxzYZSOICM/GHhxKM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaiSuryaPrabu/deep_learning/blob/main/2_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of data"
      ],
      "metadata": {
        "id": "Ts6nofwSLMy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "X,y = make_circles(n_samples=1000,noise=0.35,random_state=42)\n",
        "X[:5],y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbeuQh2nLPCS",
        "outputId": "6e2abd88-8ae3-4db8-a09c-76e401da9877"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.56161627,  0.47476109],\n",
              "        [-0.40213357,  0.40018308],\n",
              "        [-1.04686044,  0.95211341],\n",
              "        [-0.96020855,  0.36244147],\n",
              "        [ 0.49652102, -0.86811738]]),\n",
              " array([1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data"
      ],
      "metadata": {
        "id": "oOXwoqtzLyF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
        "\n",
        "x_train.shape,y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgfCDunNL0IE",
        "outputId": "d9b81a9e-7a19-42de-e1f7-45388ef4c4d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 2), (800,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To tensors"
      ],
      "metadata": {
        "id": "0XIfF6PFMJfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "x_train = torch.from_numpy(x_train).type(torch.float).to(device)\n",
        "x_test = torch.from_numpy(x_test).type(torch.float).to(device)\n",
        "y_train = torch.from_numpy(y_train).type(torch.float).to(device)\n",
        "y_test = torch.from_numpy(y_test).type(torch.float).to(device)\n",
        "\n",
        "x_train.size(),y_train.size(),x_test.size(),y_test.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WVLcHquMLs_",
        "outputId": "b8162841-6d65-4cbc-8662-58043f7bdeff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([800, 2]),\n",
              " torch.Size([800]),\n",
              " torch.Size([200, 2]),\n",
              " torch.Size([200]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model - Linear"
      ],
      "metadata": {
        "id": "p4bQ374-NaPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building"
      ],
      "metadata": {
        "id": "8Aup1sbRNbcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # parameters\n",
        "        self.layer1 = nn.Linear(in_features=2,out_features=10)\n",
        "        self.layer2 = nn.Linear(in_features=10,out_features=10)\n",
        "        self.layer3 = nn.Linear(in_features=10,out_features=1)\n",
        "\n",
        "    def forward(self,input):\n",
        "        return self.layer3(self.layer2(self.layer1(input)))"
      ],
      "metadata": {
        "id": "dzdSGC39Ncnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = classifier().to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax7CVY2GONO7",
        "outputId": "1e00bda3-9bc7-4a79-a621-abb7fa6e3bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (layer1): Linear(in_features=2, out_features=10, bias=True)\n",
              "  (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (layer3): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and Optimizer"
      ],
      "metadata": {
        "id": "GRF7EPJGOaoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "lzECTkw4Oc6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing phase"
      ],
      "metadata": {
        "id": "fhPNnOfSPeI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # training mode\n",
        "    model.train()\n",
        "\n",
        "    y_preds = torch.round(torch.sigmoid(model(x_train).squeeze()))\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(y_preds,y_train)\n",
        "\n",
        "    # zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # take a step\n",
        "    optimizer.step()\n",
        "\n",
        "    # testing mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        test_pred = torch.round(torch.sigmoid(model(x_test).squeeze()))\n",
        "\n",
        "        test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch} Training loss {loss} Testing loss {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV-mKijEPhyE",
        "outputId": "93275cad-b163-4de8-aeaa-f9ad65338942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 10 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 20 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 30 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 40 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 50 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 60 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 70 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 80 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n",
            "Epoch 90 Training loss 0.7111011147499084 Testing loss 0.6924488544464111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model - Non linear"
      ],
      "metadata": {
        "id": "vxJv-X87Q202"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To provide flexiblity or squiggle to the NN we introduce the **activation functions** to the model"
      ],
      "metadata": {
        "id": "VY0Qt3brRF27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CurvyClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # parameters \n",
        "        self.layer1 = nn.Linear(in_features=2,out_features=10)\n",
        "        self.layer2 = nn.Linear(in_features=10,out_features=10)\n",
        "        self.layer3 = nn.Linear(in_features=10,out_features=10)\n",
        "        self.layer4 = nn.Linear(in_features=10,out_features=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        return self.layer4( self.relu ( self.layer3( self.relu( self.layer2( self.relu( self.layer1( input ) ) ) ) ) ) )\n",
        "        "
      ],
      "metadata": {
        "id": "Us79eimhQ1qq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curvy_model = CurvyClassifier().to(device)\n",
        "curvy_model"
      ],
      "metadata": {
        "id": "Cxfspa_cTYmq",
        "outputId": "b43d0300-c9f1-4a52-f311-65935601edd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CurvyClassifier(\n",
              "  (layer1): Linear(in_features=2, out_features=10, bias=True)\n",
              "  (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (layer4): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params = curvy_model.parameters(),\n",
        "                            lr = 0.1)"
      ],
      "metadata": {
        "id": "L-opcJCSTmsZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # training phase\n",
        "    curvy_model.train()\n",
        "\n",
        "    # predict\n",
        "    pred = curvy_model(x_train).squeeze()\n",
        "    y_pred = torch.round( torch.sigmoid ( pred ) )\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(y_pred,y_train)\n",
        "\n",
        "    # zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # step\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0 :\n",
        "        # testing mode\n",
        "        curvy_model.eval()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            # predict\n",
        "            pred = curvy_model(x_test).squeeze()\n",
        "            test_pred = torch.round( torch.sigmoid (pred))\n",
        "\n",
        "            # loss\n",
        "            test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "            print(f\"Epoch {epoch} Training loss {loss} Testing loss {test_loss}\")"
      ],
      "metadata": {
        "id": "xsxcnFcWUVcv",
        "outputId": "d6399522-fdd0-40cc-966a-ce8e029664fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 100 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 200 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 300 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 400 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 500 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 600 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 700 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 800 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n",
            "Epoch 900 Training loss 0.8132616877555847 Testing loss 0.8132616877555847\n"
          ]
        }
      ]
    }
  ]
}